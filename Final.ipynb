{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2eaaa3d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8baa4abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 and 30 files for training and testing, respectively.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "pathdir = \"./files_batch_1,2/\"\n",
    "files = glob.glob(os.path.join(pathdir, \"*/*\"))\n",
    "\n",
    "train = []\n",
    "test  = []\n",
    "for i in files:\n",
    "    if 'files_bfusmalljar_' in i:\n",
    "        train.append(i)\n",
    "    else:\n",
    "        test.append(i)\n",
    "print('There are {} and {} files for training and testing, respectively.'.format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007a9e3",
   "metadata": {},
   "source": [
    "## Extract the exposure part of sample\n",
    "#### P.S., In batch2, the 'water' folder is considered as 'humidity' to be consistent with batch1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f086717d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test data are loaded and combined with length 2700 and 2700, respectively, i.e., (30 * 90 rows as the exposure timestamp for each sample).\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "read_df_sample = pd.read_csv(train[0])\n",
    "features = [i for i in read_df_sample if re.findall(\"\\As\\d\", i)]\n",
    "features.append('humidity')\n",
    "features.append('label')\n",
    "\n",
    "def load_data(data):\n",
    "    all_batches = []\n",
    "    for i in data:\n",
    "        batch = pd.read_csv(i)\n",
    "\n",
    "        batch = batch.loc[batch['trial_state'] == 'exposure']\n",
    "\n",
    "        try:\n",
    "            batch['label']\n",
    "        except:\n",
    "            batch = batch.assign(label=['humidity' for _ in range(len(batch))])\n",
    "\n",
    "        batch = batch[features] # Thanks Pegah :)\n",
    "        all_batches.append(batch)\n",
    "    return all_batches\n",
    "\n",
    "train, test = pd.concat(load_data(train)), pd.concat(load_data(test))\n",
    "print('Train and test data are loaded and combined with length {} and {}, respectively, i.e., (30 * 90 rows as the exposure timestamp for each sample).'.format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe898e",
   "metadata": {},
   "source": [
    "## Encoding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b7aa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh       900\n",
      "humidity    900\n",
      "moldy       900\n",
      "Name: label, dtype: int64 \n",
      "\n",
      " fresh       990\n",
      "moldy       900\n",
      "humidity    810\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['label'].value_counts(dropna=False),'\\n\\n',test['label'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb002160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fresh': 0, 'humidity': 1, 'moldy': 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['label'].unique().tolist()\n",
    "labs = {}\n",
    "count = 0\n",
    "for lble in labels:\n",
    "    labs[lble] = labs.get(lble,0)+count\n",
    "    count += 1\n",
    "labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514eba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(data):\n",
    "    for i in labs:\n",
    "        data.loc[data['label'] == i, 'label'] = labs[i]\n",
    "    return data\n",
    "\n",
    "train, test = label_encoder(train), label_encoder(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018480c1",
   "metadata": {},
   "source": [
    "## Feature Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc8edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "label_train, label_test = np.asarray(train['label']), np.asarray(test['label'])\n",
    "features_train, features_test = np.asarray(train.drop(columns='label')), np.asarray(test.drop(columns='label'))\n",
    "\n",
    "# norm = StandardScaler().fit(features_train)\n",
    "norm = MinMaxScaler().fit(features_train)\n",
    "\n",
    "features_train, features_test = norm.transform(features_train), norm.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2febaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(features_train)//90\n",
    "def feat_ext(data, label):\n",
    "    labels = []\n",
    "    all_data = []\n",
    "    for sn in range(num_samples):\n",
    "        tmp_sample = data[sn*90:(sn+1)*90,:]\n",
    "        all_data.append(tmp_sample.max(axis=0))\n",
    "        labels.append(label[sn*90+1])\n",
    "    return all_data, labels\n",
    "\n",
    "features_train, label_train = feat_ext(features_train, label_train)\n",
    "features_test, label_test = feat_ext(features_test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57c0696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def shufflee(data,labels):\n",
    "    df = pd.DataFrame(data, columns = [str(i) for i in range(np.shape(data)[1])])\n",
    "    df = df.assign(label=labels)\n",
    "    df = shuffle(df)\n",
    "    labelss = np.asarray(df['label'])\n",
    "    featuress = np.asarray(df.drop(columns='label'))\n",
    "    return featuress, labelss\n",
    "\n",
    "features_train, label_train = shufflee(features_train, label_train)\n",
    "features_test, label_test   = shufflee(features_test, label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9aab7",
   "metadata": {},
   "source": [
    "## Classififcation based on normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16657793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: 0.333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "\n",
    "LSVM = LinearSVC(random_state=0, penalty='l2')\n",
    "LSVM.fit(features_train, label_train)\n",
    "predicted_LSVM = LSVM.predict(features_test)\n",
    "\n",
    "print('The accuracy score: {:.3f}'.format(metrics.accuracy_score(label_test, predicted_LSVM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a71013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score: 0.367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=2)\n",
    "KNN.fit(features_train, label_train)\n",
    "predicted_KNN = KNN.predict(features_test)\n",
    "\n",
    "print('The accuracy score: {:.3f}'.format(metrics.accuracy_score(label_test, predicted_KNN)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3d1bf",
   "metadata": {},
   "source": [
    "## Picking the model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b8be648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(KNN, open('knnModel.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
